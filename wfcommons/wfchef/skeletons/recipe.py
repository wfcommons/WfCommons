#!/usr/bin/env python
# -*- coding: utf-8 -*-
#
# Copyright (c) 2020 The WorkflowHub Team.
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.

from typing import Dict, List, Optional, Union, Set

from wfcommons.generator.workflow.abstract_recipe import WorkflowRecipe
from wfcommons.common.file import FileLink
from wfcommons.common.task import Task
from wfcommons.common.workflow import Workflow

from wfchef.duplicate import duplicate_nodes, duplicate


from itertools import product
import pathlib 
import pickle
import networkx as nx
import numpy as np
import pandas as pd
import json
from uuid import uuid4

this_dir = pathlib.Path(__file__).resolve().parent


class SkeletonRecipe(WorkflowRecipe):
    """A Skeleton workflow recipe class for creating synthetic workflow traces.

    :param num_pairs: The number of pair of signals to estimate earthquake STFs.
    :type num_pairs: int
    :param data_footprint: The upper bound for the workflow total data footprint (in bytes).
    :type data_footprint: int
    :param num_tasks: The upper bound for the total number of tasks in the workflow.
    :type num_tasks: int
    """

    def __init__(self,
                 graph: nx.DiGraph,
                 data_footprint: Optional[int] = 0,
                 num_tasks: Optional[int] = 3,
                 **kwargs) -> None:
        super().__init__("Skeleton", data_footprint, num_tasks)
        self.graph = graph
        self.node_types = [
            self.graph.nodes[node]["type"]
            for node in self.graph.nodes
        ]

    @classmethod
    def generate_nx_graph(cls, num_tasks: int, exclude_graphs: Set[str]) -> nx.DiGraph:
        summary_path = this_dir.joinpath("microstructures", "summary.json")
        summary = json.loads(summary_path.read_text())

        metric_path = this_dir.joinpath("metric", "err.csv")
        df = pd.read_csv(str(metric_path), index_col=0)
        df = df.drop(exclude_graphs, axis=0, errors="ignore")
        df = df.drop(exclude_graphs, axis=1, errors="ignore")
        for col in df.columns:
            df.loc[col, col] = np.nan

        reference_orders = [summary["base_graphs"][col]["order"] for col in df.columns]
        idx = np.argmin([abs(num_tasks - ref_num_tasks) for ref_num_tasks in reference_orders])
        reference = df.columns[idx]

        base = df.index[df[reference].argmin()]
        graph = duplicate(this_dir.joinpath("microstructures"), base, num_tasks)
        return graph

    @classmethod
    def from_num_tasks(cls, num_tasks: int, exclude_graphs: Set[str]) -> 'SkeletonRecipe':
        """
        Instantiate a Skeleton workflow recipe that will generate synthetic workflows up to
        the total number of tasks provided.

        :param num_tasks: The upper bound for the total number of tasks in the workflow (at least 3).
        :type num_tasks: int

        :return: A Skeleton workflow recipe object that will generate synthetic workflows up
                 to the total number of tasks provided.
        :rtype: SkeletonRecipe
        """
        return SkeletonRecipe(graph=cls.generate_nx_graph(num_tasks, exclude_graphs), num_tasks=num_tasks)

    def _load_base_graph(self) -> nx.DiGraph:
        return pickle.loads(this_dir.joinpath("base_graph.pickle").read_bytes())

    def _load_microstructures(self) -> Dict:
        return json.loads(this_dir.joinpath("microstructures.json").read_text())

    def build_workflow(self, workflow_name: Optional[str] = None) -> Workflow:
        """Generate a synthetic workflow trace of a Skeleton workflow.

        :param workflow_name: The workflow name
        :type workflow_name: int

        :return: A synthetic workflow trace object.
        :rtype: Workflow
        """
        workflow = Workflow(name=self.name + "-synthetic-trace" if not workflow_name else workflow_name, makespan=None)
        graph = self.graph.copy()

        task_names = {}
        for node in graph.nodes:
            if node in ["SRC", "DST"]:
                continue
            node_type = graph.nodes[node]["type"]
            task_name = self._generate_task_name(node_type)
            task = self._generate_task(node_type, task_name)
            workflow.add_node(task_name, task=task)

            task_names[node] = task_name

        for (src, dst) in graph.edges:
            if src in ["SRC", "DST"] or dst in ["SRC", "DST"]:
                continue
            workflow.add_edge(task_names[src], task_names[dst])        
        
        workflow.nxgraph = graph
        self.workflows.append(workflow)
        return workflow

    def _workflow_recipe(self) -> Dict:
        """
        Recipe for generating synthetic traces of the Skeleton workflow. Recipes can be
        generated by using the :class:`~workflowhub.trace.trace_analyzer.TraceAnalyzer`.

        :return: A recipe in the form of a dictionary in which keys are task prefixes.
        :rtype: Dict[str, Any]
        """
        # default = json.loads(this_dir.joinpath("default.json").read_text()) -- do something like this (maybe =)
        default = {
            "runtime": {
                "min": 0.087,
                "max": 5.615,
                "distribution": {
                    "name": "alpha",
                    "params": [
                        2.8535577839854487e-09,
                        -0.6968250029499959,
                        1.0879675561652093
                    ]
                }
            },
            "input": {
                ".lht": {
                    "distribution": {
                        "name": "fisk",
                        "params": [
                            0.4312877358390993,
                            -5.198983213279189e-26,
                            2.042713032349936
                        ]
                    },
                    "min": 1024,
                    "max": 16012
                }
            },
            "output": {
                ".stf": {
                    "distribution": {
                        "name": "argus",
                        "params": [
                            1.3444573433417438e-05,
                            -2922.408647942764,
                            6738.674391937242
                        ]
                    },
                    "min": 1144,
                    "max": 17016
                }
            }
        }
        return {
            node_type: default
            for node_type in self.node_types
        }
